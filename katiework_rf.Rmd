---
title: "katiework2"
output: html_document
date: '2022-03-12'
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(tidyr)
library(ggplot2)
library(dplyr)

# install.packages("randomForest")
library(randomForest)
#install.packages("gbm")
library(gbm)
library(ISLR)
library(tree)
```

## Loading Data

```{r}
data = read.csv('marketing_campaign.csv', sep = '\t')  # load data
head(data)  # print first 5 rows of data
```

```{r}
df = data.frame(data)
```

#### Check for and remove missing values

```{r}
missing.values <- df %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)
```

```{r}
df1=na.omit(df)
```

#### Calculating, combining, and creating variables

Combining the variables to get the number of children from the customers

```{r}
df1['Age']= 2022 - df1$Year_Birth
df1['Child']=df1$Kidhome+df1$Teenhome
```

```{r}
print(min(df1$Dt_Customer))
print(max(df1$Dt_Customer))

```

Combining the spend amounts for items

```{r}
df1['total_spent']=df1$MntMeatProducts+df1$MntFishProducts+df1$MntWines+df1$MntFruits+df1$MntSweetProducts+df1$MntGoldProds
```

Combining the number of children

```{r}
df1["Children"] <- df1["Kidhome"] + df1["Teenhome"]
df1 <- df1[,!(names(data) == "Kidhome" | names(df1) == "Teenhome")]
head(df1)
```

Create a column for the total number of accepted promotions

```{r}
df1["TotalAcceptedCmp"] <- data["AcceptedCmp1"] + data["AcceptedCmp2"] +
  data["AcceptedCmp3"] + data["AcceptedCmp4"] + data["AcceptedCmp5"] + data["Response"]

del_accep_cmp <- c("AcceptedCmp1", "AcceptedCmp2", "AcceptedCmp3", "AcceptedCmp4", "AcceptedCmp5", "Response")

df1 <- df1[,!(names(df1) %in% del_accep_cmp)]
head(df1)
```

Number of day customer enroll with the company (until 07/31/2021)

-   Calculate days difference between the day customer enrolled with the company and the day the author uploaded the data on Kaggle, 07/31/2021.

```{r}
df$Dt_CustomerCovert1 = as.Date(df$Dt_Customer)
df$Dt_CustomerCovert2 = as.Date("2021-07-31") - as.Date(df$Dt_CustomerCovert1)
df$NumberofDayEnrolled = as.numeric(df$Dt_CustomerCovert2, units="days")
df1["NumDaysEnrolled"] <- df["NumberofDayEnrolled"] 
```

```{r}
names(df1)
```

#### Remove unnecessary variables

We only need the customers' general information to predict the amount spent on different product categories.

```{r}
# 1 - ID : 2 - Year_Birth
# 6 - Dt_Customer 
# 19 - Complain : 23 - Child

df1 <- df1[-c( 1:2 , 6,  19:23 )]

```

```{r}
names(df1)
```

#### Detecting and Removing Outliers

```{r}
df1 <- df1[!(df1$Income>150000 | 
            df1$MntMeatProducts>1000 |
            df1$MntSweetProducts>200 | 
            df1$MntGoldProds>260 ) , ]
```

#### Handle missing data

```{r}
df1 <- df1[!(is.na(df1$Income)),]
```

#### Convert the categories "Education", "Marital_Status", and "Complain" to factors

```{r}
df1$Education <- as.factor(df1$Education)
df1$Marital_Status <- as.factor(df1$Marital_Status)
#df1$Complain <- as.factor(df1$Complain)
df1$AcceptedCmp <- as.factor(ifelse(df1$TotalAcceptedCmp > 0, 1, 0))
```

## Reducing Categories

#### See how frequently each marital status occurs

```{r}
MarritalStatfreq <- data.frame(table(df1$Marital_Status))
MarritalStatfreq[order(MarritalStatfreq$Freq, decreasing = TRUE),]
```

#### List marital status that appear in the at least 1% of the records

```{r}
MarritalStatfreq[MarritalStatfreq$Freq / nrow(df1) > .01, ]
```

#### Combine all other marital status into "Other"

8 statuses for "Marital Status" variable

Only 5 appear in at least 1% of the records, so other 3 will go into "Other"

```{r}
df1$Marital_Status <- as.factor(ifelse(df1$Marital_Status %in% 
                                               c("Divorced", "Married", "Single","Together","Widow"), 
                                        as.character(df1$Marital_Status), 
                                        "Other"))
MarritalStatfreq <- data.frame(table(df1$Marital_Status))
MarritalStatfreq[order(MarritalStatfreq$Freq, decreasing = TRUE),]
```

#### Create Dummy variable

Create binary dummy variables (0 and 1) for three categorical variables, Education, Marital_Status, and AcceptedCmp. Then remove the original columns.

```{r}
library( fastDummies )
df1 <- dummy_cols(df1,
                  select_columns = c("Education", "Marital_Status","AcceptedCmp" ),
                           remove_first_dummy = TRUE,
                           remove_selected_columns = TRUE )
```

#### Splitting Data into training and test sets

Splitting into 70% train, 30% test data

```{r}
df1_subset <- df1[ , -c(5:9)]

set.seed(123)
train.rows <- sample(rownames( df1_subset), nrow( df1_subset )*0.7)
train.data <- df1_subset[train.rows , ]
test.rows <- setdiff(rownames( df1_subset), train.rows)
test.data <- df1_subset[test.rows , ]
```

```{r}
head(train.data)
```

### Random Forest

combination predictions from many trees

## Predicting whether a customer will respond to a promotion or not

#### Building the random forest model

```{r}
library(randomForest)
df1_rf_promo <- randomForest(as.factor(TotalAcceptedCmp)  ~ ., data=train.data, ntree=500,mtry = 4)

df1_rf_promo
```

We see from calling "df1_rf_promo" that the the Out of Bag (OOB) estimate of error rate is 11.8% for 500 trees.

The confusion matrix is a good way of assessing the performance of the classifier when it is presented with new data.

```{r}
print(df1_rf_promo)
```

```{r}
plot(df1_rf_promo)
```

From the plot, out of 500 trees, we see that improvement steadies out as the number of trees increase. We see from the plot that the error is the lowest around less than 100 trees or at 100 trees.

```{r}
importance(df1_rf_promo)
```

```{r}
varImpPlot(df1_rf_promo, sort=T, main="Variable Importance for df1_rf_promo")
```

From the importance() function and varImpPlot(), we are able to both quantify and visualize the importance of each variable. From both the table and plot, we see that the most significant variables in determining a customer's response to a promotion are "AcceptedCmp_1", "NumDaysEnrolled", "Income", "Recency", and "total_spent".

From this information, this indicates that the most significant factors in determining a customers' response to a promotion are if that customer has responded to or accepted promotions before, the number of days they've enrolled with the company, their income, the number of days since their last purchase, and the amount they spend.

```{r}
varImpPlot(df1_rf_promo, sort=T, main="Top 5 Variables' Importance for df1_rf_promo", n.var=5)
```

Here, we can visualize with better ease of the top five variables' importance in determining a customer's response to a promotion or campaign.

#### Finding the test error rate

```{r}
yhat.rf = predict (df1_rf_promo, newdata = test.data)
# Confusion matrix
rf.err = table(pred = yhat.rf, truth = test.data$TotalAcceptedCmp)
test.rf.err = 1 - sum(diag(rf.err))/sum(rf.err)
test.rf.err
```

The test set error rate is 0.1059. This indicates that this model's accuracy is a great improvement.

#### Fine Tuning by finding the best mtry

Two parameters that are important in the random forest algorithm are the number of trees used in the forest, and the number of random variables used in each tree.

Here, we see if we can find the best mtry for the random forest model.

One of the biggest factors that has the biggest effect on the final accuracy of the model is the mtry. The mtry is the number of variables randomly sampled as candidates at each split. As we see from the figure below, as the number of predictors sampled increases, the error goes down. However, having a high mtry can also make the model prone to overfitting.

```{r}
mtry <- tuneRF(train.data[-20], train.data$TotalAcceptedCmp, ntreeTry=500, 
               stepFactor=1.5, improve=0.01, trace=TRUE, plot=TRUE)
```

**The total amount spent on products** are very highly correlated with whether the customer responded to the marketing campaign.

In the end, we find that **Income and Total Amount Spent are very correlated**. Customers who earn more spend more.

**Customers who have recently purchased something aremore likely to respond** to the marketing campaign. This makes senses because when a customer has more recent purchases they have more of a probable pattern of shopping at the store.
